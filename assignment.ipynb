{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d36d05f1",
   "metadata": {},
   "source": [
    "# ML Assignment — Fish Weight Prediction\n",
    "\n",
    "This notebook:\n",
    "- Loads `Fish.csv` with **pandas**\n",
    "- Visualizes `Weight` vs the other features with **seaborn**\n",
    "- Builds a **scikit-learn Pipeline** for preprocessing + regression\n",
    "- Compares a **baseline** vs **Ridge regression** (you can swap to Lasso / ElasticNet easily)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45290e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import Ridge  # swap to Lasso or ElasticNet if desired\n",
    "\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c836510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "csv_path = \"Fish.csv\"  # assumes Fish.csv is in the repo root next to this notebook\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "df.head(), df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af650c",
   "metadata": {},
   "source": [
    "## Pairplot: `Weight` vs all other numeric features\n",
    "\n",
    "`seaborn.pairplot` works best with numeric features.  \n",
    "`Species` is categorical, so we use it as a **hue** (color) and pairplot `Weight` against all other *numeric* features.\n",
    "\n",
    "We also add a quick plot of `Weight` by `Species` to include the categorical feature in the EDA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7779e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot Weight vs numeric features, colored by Species\n",
    "numeric_features = [c for c in df.columns if c not in [\"Species\", \"Weight\"]]\n",
    "\n",
    "sns.pairplot(\n",
    "    df,\n",
    "    x_vars=numeric_features,\n",
    "    y_vars=[\"Weight\"],\n",
    "    hue=\"Species\",\n",
    "    height=3,\n",
    "    aspect=1.2\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Bonus: show Weight distribution by Species (categorical feature)\n",
    "plt.figure()\n",
    "sns.boxplot(data=df, x=\"Species\", y=\"Weight\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558bdc48",
   "metadata": {},
   "source": [
    "## Train/test split + preprocessing\n",
    "\n",
    "- **Target**: `Weight`\n",
    "- **Features**: `Species` (categorical) + all length/height/width fields (numeric)\n",
    "- Preprocessing:\n",
    "  - One-hot encode `Species`\n",
    "  - Standardize numeric columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975873a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Weight\"])\n",
    "y = df[\"Weight\"]\n",
    "\n",
    "categorical_features = [\"Species\"]\n",
    "numeric_features = [c for c in X.columns if c not in categorical_features]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f32ae5",
   "metadata": {},
   "source": [
    "## Baseline vs Ridge (Pipeline)\n",
    "\n",
    "Baseline: `DummyRegressor(strategy=\"mean\")` — predicts the mean weight from the training set.\n",
    "\n",
    "Model: **Ridge regression** inside a Pipeline (preprocessing → model).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62076478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_train, X_test, y_train, y_test, name=\"model\"):\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    return {\"name\": name, \"RMSE\": rmse, \"MAE\": mae, \"R2\": r2}\n",
    "\n",
    "baseline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", DummyRegressor(strategy=\"mean\")),\n",
    "])\n",
    "\n",
    "ridge = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", Ridge(alpha=1.0, random_state=RANDOM_STATE)),\n",
    "])\n",
    "\n",
    "results = [\n",
    "    evaluate(baseline, X_train, X_test, y_train, y_test, name=\"Baseline (mean)\"),\n",
    "    evaluate(ridge, X_train, X_test, y_train, y_test, name=\"Ridge\"),\n",
    "]\n",
    "\n",
    "pd.DataFrame(results).sort_values(\"RMSE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4013d727",
   "metadata": {},
   "source": [
    "## Cross-validation (optional but nice)\n",
    "\n",
    "A single train/test split can be noisy on small datasets, so here’s a quick 5-fold CV RMSE comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8497488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# scikit-learn uses negative values for loss metrics in cross_val_score\n",
    "baseline_cv = -cross_val_score(\n",
    "    baseline, X, y, cv=cv, scoring=\"neg_root_mean_squared_error\"\n",
    ").mean()\n",
    "\n",
    "ridge_cv = -cross_val_score(\n",
    "    ridge, X, y, cv=cv, scoring=\"neg_root_mean_squared_error\"\n",
    ").mean()\n",
    "\n",
    "pd.DataFrame([\n",
    "    {\"model\": \"Baseline (mean)\", \"CV_RMSE\": baseline_cv},\n",
    "    {\"model\": \"Ridge\", \"CV_RMSE\": ridge_cv},\n",
    "]).sort_values(\"CV_RMSE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5387cfa7",
   "metadata": {},
   "source": [
    "## Git steps (run in your terminal)\n",
    "\n",
    "> I can’t directly push to your GitHub from here, but these are the exact commands you should run.\n",
    "\n",
    "```bash\n",
    "# 1) Create a new branch with your name\n",
    "git checkout -b <your-name>\n",
    "\n",
    "# 2) Add the notebook\n",
    "git add assignment.ipynb\n",
    "\n",
    "# 3) Commit\n",
    "git commit -m \"Add ML assignment notebook\"\n",
    "\n",
    "# 4) Push\n",
    "git push -u origin <your-name>\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
